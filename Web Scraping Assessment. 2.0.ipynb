{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d23a8e",
   "metadata": {},
   "source": [
    "# WEB SCRAPING (Using Selenium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed75f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b95acf",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data. \n",
    "This task will be done in following steps: \n",
    "1. First get the webpage https://www.naukri.com/ 2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field. \n",
    "3. Then click the search button. \n",
    "4. Then scrape the data for the first 10 jobs results you get. \n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dffb25a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-5d79736bd70a>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\")\n",
      "<ipython-input-2-5d79736bd70a>:9: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\") #job search bar\n",
      "<ipython-input-2-5d79736bd70a>:10: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_field_location=driver.find_element_by_id('qsb-location-sugg') #location search bar\n",
      "<ipython-input-2-5d79736bd70a>:16: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
      "<ipython-input-2-5d79736bd70a>:29: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
      "<ipython-input-2-5d79736bd70a>:38: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
      "<ipython-input-2-5d79736bd70a>:47: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
      "<ipython-input-2-5d79736bd70a>:58: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)</td>\n",
       "      <td>Data Analyst - Flipkart Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>(3776 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>Urgent Openings For Data Analyst / Business An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Business Data Analyst(BigId) - Capco - Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>(3776 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Capco Technologies Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Sr Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>(108 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Pioneer Business Solutions</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Opportunity For Business Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Pioneer Business Solutions</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Software Technologist II - Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>Hiring For Data Analyst - Payment System Intel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>Botree Software International Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>Lead / Senior Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                                   company_name  \\\n",
       "0             0-3 Yrs                                       Flipkart   \n",
       "1             1-6 Yrs                                 (3776 Reviews)   \n",
       "2             3-8 Yrs                                       Flipkart   \n",
       "3            6-11 Yrs                                 (3776 Reviews)   \n",
       "4             3-8 Yrs                     Capco Technologies Pvt Ltd   \n",
       "5             2-5 Yrs                                  (108 Reviews)   \n",
       "6             3-6 Yrs                     Pioneer Business Solutions   \n",
       "7            6-11 Yrs                     Pioneer Business Solutions   \n",
       "8             4-9 Yrs                                    AugmatrixGo   \n",
       "9             4-6 Yrs  Botree Software International Private Limited   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                     Bangalore/Bengaluru(Bellandur)   \n",
       "1            Bangalore/Bengaluru\\n(WFH during Covid)   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6            Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "9            Bangalore/Bengaluru\\n(WFH during Covid)   \n",
       "\n",
       "                                           job_title  \n",
       "0                  Data Analyst - Flipkart Analytics  \n",
       "1  Urgent Openings For Data Analyst / Business An...  \n",
       "2   Business Data Analyst(BigId) - Capco - Bangalore  \n",
       "3                                Senior Data Analyst  \n",
       "4                                    Sr Data Analyst  \n",
       "5     Business Data Analyst - Database Design/Mining  \n",
       "6              Opportunity For Business Data Analyst  \n",
       "7            Software Technologist II - Data Analyst  \n",
       "8  Hiring For Data Analyst - Payment System Intel...  \n",
       "9                         Lead / Senior Data Analyst  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# entering “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\") #job search bar\n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg') #location search bar\n",
    "search_field_designation.send_keys(\"Data Analyst\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "\n",
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "time.sleep(4)\n",
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "time.sleep(4)        \n",
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "#scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e3379e",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. \n",
    "This task will be done in following steps: \n",
    "1. First get the webpage https://www.naukri.com/ 2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field. \n",
    "3. Then click the search button. \n",
    "4. Then scrape the data for the first 10 jobs results you get. \n",
    "5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c5ac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-4dd3da40d0cf>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\")\n",
      "<ipython-input-3-4dd3da40d0cf>:10: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")   #job search bar\n",
      "<ipython-input-3-4dd3da40d0cf>:11: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_field_location=driver.find_element_by_id('qsb-location-sugg')  #location search bar\n",
      "<ipython-input-3-4dd3da40d0cf>:17: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
      "<ipython-input-3-4dd3da40d0cf>:30: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
      "<ipython-input-3-4dd3da40d0cf>:39: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
      "<ipython-input-3-4dd3da40d0cf>:48: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
      "<ipython-input-3-4dd3da40d0cf>:56: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
      "<ipython-input-3-4dd3da40d0cf>:61: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  raw_description=driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>Concentrix Daksh Services</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Roles and Responsibilities\\nThe person will be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>(10230 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Kwalee is one of the world's leading multiplat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>(2049 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru(Sadashiva Nagar)</td>\n",
       "      <td>Roles and Responsibilities\\nPhD in Statistics,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist | Fortune 500 Supermarke...</td>\n",
       "      <td>Kwalee India Pvt Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Work Experience:\\n~2+ years of relevant experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Convergence Infotech Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Essential Functions\\nServe as an analytics exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>(8 Reviews)</td>\n",
       "      <td>Mumbai, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>5+ years of experience as a data scientist, ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>TALENT500 TECH (INDIA) PRIVATE LIMITED</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Roles and Responsibilities\\n\\nWell-versed in q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist / Tech Lead - SQL / Pyth...</td>\n",
       "      <td>Visa</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Responsibilities :\\n\\n- Lead a team of data sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "      <td>(37 Reviews)</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Requirement:\\nWe are looking for an experience...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0    Forecasting Analyst/ Data Scientist (US Client)   \n",
       "1                                     Data Scientist   \n",
       "2                              Senior Data Scientist   \n",
       "3                              Senior Data Scientist   \n",
       "4  Senior Data Scientist | Fortune 500 Supermarke...   \n",
       "5                                     Data Scientist   \n",
       "6                                Lead Data Scientist   \n",
       "7                                Lead Data Scientist   \n",
       "8  Senior Data Scientist / Tech Lead - SQL / Pyth...   \n",
       "9                       Senior / Lead Data Scientist   \n",
       "\n",
       "                             company_name  \\\n",
       "0               Concentrix Daksh Services   \n",
       "1                         (10230 Reviews)   \n",
       "2                  Oracle India Pvt. Ltd.   \n",
       "3                          (2049 Reviews)   \n",
       "4                   Kwalee India Pvt Ltd.   \n",
       "5                Convergence Infotech Ltd   \n",
       "6                             (8 Reviews)   \n",
       "7  TALENT500 TECH (INDIA) PRIVATE LIMITED   \n",
       "8                                    Visa   \n",
       "9                            (37 Reviews)   \n",
       "\n",
       "                                        job_location  \\\n",
       "0              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3               Bangalore/Bengaluru(Sadashiva Nagar)   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                  Mumbai, Pune, Bangalore/Bengaluru   \n",
       "7  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "8                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "9  Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru   \n",
       "\n",
       "                                     job_description  \n",
       "0  Roles and Responsibilities\\nThe person will be...  \n",
       "1                                                ---  \n",
       "2  Kwalee is one of the world's leading multiplat...  \n",
       "3  Roles and Responsibilities\\nPhD in Statistics,...  \n",
       "4  Work Experience:\\n~2+ years of relevant experi...  \n",
       "5  Essential Functions\\nServe as an analytics exp...  \n",
       "6  5+ years of experience as a data scientist, ap...  \n",
       "7  Roles and Responsibilities\\n\\nWell-versed in q...  \n",
       "8  Responsibilities :\\n\\n- Lead a team of data sc...  \n",
       "9  Requirement:\\nWe are looking for an experience...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# entering “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")   #job search bar\n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg')  #location search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "full_job_description=[]\n",
    "\n",
    "\n",
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "time.sleep(4)\n",
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "time.sleep(4)        \n",
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "# scraping the full job-description, for scraping full job description we have to go in each of the jobs separately\n",
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "for url in urls[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n",
    "        description=raw_description.replace(\"Contact Person\",\"@@@@@\")\n",
    "        description= description.split(\"@@@@@\")\n",
    "        full_job_description.append(description[0])\n",
    "    except NoSuchElementException :\n",
    "        full_job_description.append(\"---\")\n",
    "        \n",
    "        \n",
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_description\":full_job_description[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781182f",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below: \n",
    "\n",
    "You have to use the location and salary filter. \n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results. \n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs \n",
    "The task will be done as shown in the below steps: \n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field. \n",
    "3. Then click the search button. \n",
    "4. Then apply the location filter and salary filter by checking the respective boxes \n",
    "5. Then scrape the data for the first 10 jobs results you get. \n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# entering “Data Scientist” in “Skill,Designations,Companies” field\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")   #job  search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "#finding the delhi/ncr check box\n",
    "loc=driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/p\")\n",
    "loc.click()\n",
    "\n",
    "time.sleep(2)\n",
    "# finding the salary check box\n",
    "slry_box = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/p\")\n",
    "slry_box.click()\n",
    "\n",
    "time.sleep(3)\n",
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "#scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "            \n",
    "time.sleep(3)            \n",
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\n",
    "                 \"job_location\":job_location[0:10]})\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a77616",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: \n",
    "1. Brand \n",
    "2. Product Description \n",
    "3. Price \n",
    "The attributes which you have to scrape is ticked marked in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb6b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-5ff3155d8002>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\")\n",
      "<ipython-input-6-5ff3155d8002>:9: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
      "<ipython-input-6-5ff3155d8002>:14: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  button=driver.find_element_by_class_name('L0Z3Pu')\n",
      "<ipython-input-6-5ff3155d8002>:30: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
      "<ipython-input-6-5ff3155d8002>:33: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  desc=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')#scraping description from the xpath\n",
      "<ipython-input-6-5ff3155d8002>:36: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
      "<ipython-input-6-5ff3155d8002>:39: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.send_keys('sunglasses')\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "#scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    desc=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe935ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-1dfc37f6b604>:6: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  url=driver.find_elements_by_xpath(\"//a[@class='_2UzuFa']\")\n",
      "<ipython-input-7-1dfc37f6b604>:9: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
      "<ipython-input-7-1dfc37f6b604>:20: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  disc=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[3]/div/div[3]/div[1]/div/div[3]/span\")# scraping the discount from the absolute xpath\n"
     ]
    }
   ],
   "source": [
    "#scrapping all product Url\n",
    "product_url = []\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    url=driver.find_elements_by_xpath(\"//a[@class='_2UzuFa']\")\n",
    "    for i in url:\n",
    "        product_url.append(i.get_attribute('href'))\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))     #getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "\n",
    "# scraping discount from each product url\n",
    "for product in product_url:\n",
    "    driver.get(product)\n",
    "    try:\n",
    "        disc=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[3]/div/div[3]/div[1]/div/div[3]/span\")# scraping the discount from the absolute xpath\n",
    "        discount.append(disc.text)\n",
    "    except NoSuchElementException:\n",
    "        discount.append(\"No Discount\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35f87a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,085</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Round Sungl...</td>\n",
       "      <td>₹276</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹248</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹513</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Round Sunglasses (53)</td>\n",
       "      <td>₹249</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Retro Squar...</td>\n",
       "      <td>₹258</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Cruze</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹509</td>\n",
       "      <td>No Discount</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand                                        Description   Price  \\\n",
       "0      Fastrack              UV Protection Aviator Sunglasses (58)  ₹1,085   \n",
       "1      Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹758   \n",
       "2        SUNBEE  UV Protection, Polarized, Mirrored Round Sungl...    ₹276   \n",
       "3     Elligator                UV Protection Round Sunglasses (54)    ₹248   \n",
       "4      Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹513   \n",
       "..          ...                                                ...     ...   \n",
       "115    Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹758   \n",
       "116  PHENOMENAL                UV Protection Round Sunglasses (53)    ₹249   \n",
       "117      SUNBEE  UV Protection, Polarized, Mirrored Retro Squar...    ₹258   \n",
       "118       Cruze       UV Protection Aviator Sunglasses (Free Size)    ₹499   \n",
       "119    Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...    ₹509   \n",
       "\n",
       "        Discount  \n",
       "0    No Discount  \n",
       "1    No Discount  \n",
       "2    No Discount  \n",
       "3    No Discount  \n",
       "4    No Discount  \n",
       "..           ...  \n",
       "115  No Discount  \n",
       "116  No Discount  \n",
       "117  No Discount  \n",
       "118  No Discount  \n",
       "119  No Discount  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand,\n",
    "                'Description':description,\n",
    "                'Price':price,\n",
    "                'Discount':discount})\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5e852",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC \n",
    "TSVZAXUHGREPBFGI&marketplace. When you will open the above link you will reach to the below shown webpage .\n",
    "\n",
    " you have to scrape the tick marked attributes. These are: \n",
    "1. Rating \n",
    "2. Review_summary \n",
    "3. Full review \n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26d082d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-92fea0b27ebe>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\")\n",
      "<ipython-input-9-92fea0b27ebe>:17: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  url_1 = driver.find_elements_by_xpath(\"//a[@class='ge-49M _2Kfbh8']\")\n",
      "<ipython-input-9-92fea0b27ebe>:20: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  url_2 = driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
      "<ipython-input-9-92fea0b27ebe>:29: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for j in driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\"):\n",
      "<ipython-input-9-92fea0b27ebe>:32: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
      "<ipython-input-9-92fea0b27ebe>:35: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for l in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Stars</th>\n",
       "      <th>Short Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>The ultimate performance\\nCamera is superb\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Stars       Short Review  \\\n",
       "0                5          Brilliant   \n",
       "1                5     Simply awesome   \n",
       "2                5   Perfect product!   \n",
       "3                5  Worth every penny   \n",
       "4                5          Fabulous!   \n",
       "..             ...                ...   \n",
       "95               5             Super!   \n",
       "96               5          Just wow!   \n",
       "97               5  Terrific purchase   \n",
       "98               5            Awesome   \n",
       "99               3     Decent product   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "96  The ultimate performance\\nCamera is superb\\nTh...  \n",
       "97  I use a Note10+ and have been using both iOS a...  \n",
       "98  The phone is completely good\\nAs far as camera...  \n",
       "99  Everything u ll like it when u use this iPhone...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Creating empty list\n",
    "urls=[]\n",
    "short_review=[]\n",
    "complete_review=[]\n",
    "stars=[]\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping 10 pages url\n",
    "url_1 = driver.find_elements_by_xpath(\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "for i in url_1:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "url_2 = driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
    "for i in url_2:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    #for scrapping the number of stars\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\"):\n",
    "        stars.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        short_review.append(k.text)\n",
    "    #for scrapping the complete review\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        complete_review.append(l.text)\n",
    "        \n",
    "        \n",
    "        \n",
    "#Combining all the lists into a single dataframe\n",
    "df=pd.DataFrame({'Number of Stars': stars,\n",
    "                'Short Review': short_review,\n",
    "               'Full Review': complete_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a824b09d",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field. \n",
    "You have to scrape 4 attributes of each sneaker: \n",
    "1. Brand \n",
    "2. Product Description \n",
    "3. Price \n",
    "You have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f1aecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-7fa8e78039a3>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\")\n",
      "<ipython-input-11-7fa8e78039a3>:9: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  log_in_pop_up = driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
      "<ipython-input-11-7fa8e78039a3>:14: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
      "<ipython-input-11-7fa8e78039a3>:20: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  button=driver.find_element_by_class_name('L0Z3Pu')\n",
      "<ipython-input-11-7fa8e78039a3>:36: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
      "<ipython-input-11-7fa8e78039a3>:39: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
      "<ipython-input-11-7fa8e78039a3>:42: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  disc=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")# scraping the discount from the xpath\n",
      "<ipython-input-11-7fa8e78039a3>:45: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
      "<ipython-input-11-7fa8e78039a3>:59: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  product_url = driver.find_elements_by_xpath(\"//a[@class='_2UzuFa']\")\n",
      "<ipython-input-11-7fa8e78039a3>:63: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
      "<ipython-input-11-7fa8e78039a3>:72: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  desc=driver.find_elements_by_xpath('//span[@class=\"B_NuCI\"]')#scraping description from the xpath\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men  (Red)</td>\n",
       "      <td>₹560</td>\n",
       "      <td>43% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Turino FSL Sneakers For Men  (White)</td>\n",
       "      <td>₹699</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Casual Shoe for Men Sneakers For Men  (Black)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Stylish &amp; Trendy Sneakers For Men  (Blue)</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>9019 Sneakers For Men  (White)</td>\n",
       "      <td>₹479</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jabra</td>\n",
       "      <td>Men's Ultraforce Mid-top Athletic-Inspired Ret...</td>\n",
       "      <td>₹259</td>\n",
       "      <td>48% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NBL Sports</td>\n",
       "      <td>STI-1 casual shoes for men | Latest &amp; Trending...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>HOC</td>\n",
       "      <td>Sneakers For Men  (White)</td>\n",
       "      <td>₹429</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Perfect Sports Shoes for Running Training Hiki...</td>\n",
       "      <td>₹3,359</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>U.S. POLO ASSN.</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "      <td>₹2,199</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                                        Description  \\\n",
       "0          RapidBox                            Sneakers For Men  (Red)   \n",
       "1             Echor               Turino FSL Sneakers For Men  (White)   \n",
       "2           Numenzo      Casual Shoe for Men Sneakers For Men  (Black)   \n",
       "3          Magnolia          Stylish & Trendy Sneakers For Men  (Blue)   \n",
       "4           Numenzo                     9019 Sneakers For Men  (White)   \n",
       "..              ...                                                ...   \n",
       "95            Jabra  Men's Ultraforce Mid-top Athletic-Inspired Ret...   \n",
       "96       NBL Sports  STI-1 casual shoes for men | Latest & Trending...   \n",
       "97              HOC                          Sneakers For Men  (White)   \n",
       "98             PUMA  Perfect Sports Shoes for Running Training Hiki...   \n",
       "99  U.S. POLO ASSN.  Combo pack of 2 casual sneaker shoes for men S...   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹560  43% off  \n",
       "1     ₹699  58% off  \n",
       "2     ₹499  75% off  \n",
       "3     ₹398  60% off  \n",
       "4     ₹479  63% off  \n",
       "..     ...      ...  \n",
       "95    ₹259  48% off  \n",
       "96    ₹299  70% off  \n",
       "97    ₹429  78% off  \n",
       "98  ₹3,359  58% off  \n",
       "99  ₹2,199  45% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#close log_in window\n",
    "log_in_pop_up = driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "log_in_pop_up.click()\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sneakers')\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the button and clicking it to search for sneakers\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "#scrapping the required details\n",
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "        \n",
    "        \n",
    "time.sleep(2)        \n",
    "# Since in some records not getting description so try from inside of urls\n",
    "urls = []\n",
    "\n",
    "for page in range(0,4):#for loop for scrapping 4 page\n",
    "    \n",
    "    product_url = driver.find_elements_by_xpath(\"//a[@class='_2UzuFa']\")\n",
    "    for i in product_url:\n",
    "        urls.append(i.get_attribute('href'))\n",
    "    \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "time.sleep(2)        \n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    desc=driver.find_elements_by_xpath('//span[@class=\"B_NuCI\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list\n",
    "time.sleep(2)        \n",
    "time.sleep(3)        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc0046",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes \n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image.\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe \n",
    "description, price of the shoe as shown in the below image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79ff62f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-71b76d68d971>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\")\n",
      "<ipython-input-12-71b76d68d971>:9: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  price_button = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
      "<ipython-input-12-71b76d68d971>:14: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  black_button = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.myntra.com/shoes%22\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#clicking on price filter\n",
    "price_button = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_button.click()\n",
    "\n",
    "\n",
    "#clicking on black colour\n",
    "black_button = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "black_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2826639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-bc7bf7012fd8>:10: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  nxt_page = driver.find_elements_by_xpath(\"//ul[@class='pagination-container']/li/a\")\n",
      "<ipython-input-13-bc7bf7012fd8>:17: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  Names=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")  #for scrapping shoe brand names\n",
      "<ipython-input-13-bc7bf7012fd8>:21: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  desc=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\") #for scrapping shoe short-description\n",
      "<ipython-input-13-bc7bf7012fd8>:28: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  rs=driver.find_elements_by_xpath(\"//div[@class='product-price']\")  #for scrapping shoe prices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short-description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>Chunky Combat Boots</td>\n",
       "      <td>Rs. 2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Woven Design Running Shoes</td>\n",
       "      <td>Rs. 2009Rs. 2999(33% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eego Italy</td>\n",
       "      <td>Men Trekking Shoes</td>\n",
       "      <td>Rs. 899Rs. 2599(Rs. 1700 OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Kent 2.0 IDP Sneakers</td>\n",
       "      <td>Rs. 1799Rs. 2999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MENGLER</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 724Rs. 2499(71% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Kalenji By Decathlon</td>\n",
       "      <td>Women Platform Chelsea Boots</td>\n",
       "      <td>Rs. 1597Rs. 1699(6% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Men Court Royale Sneakers</td>\n",
       "      <td>Rs. 2099Rs. 6999(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Sir Corbett</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 809Rs. 2699(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Heeled Boots</td>\n",
       "      <td>Rs. 3199Rs. 3999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>El Paso</td>\n",
       "      <td>Men Runesy Shoes</td>\n",
       "      <td>Rs. 1299Rs. 4799(Rs. 3500 OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand               Short-description  \\\n",
       "0                    H&M             Chunky Combat Boots   \n",
       "1                 ADIDAS  Men Woven Design Running Shoes   \n",
       "2             Eego Italy              Men Trekking Shoes   \n",
       "3                   Puma    Unisex Kent 2.0 IDP Sneakers   \n",
       "4                MENGLER               Men Walking Shoes   \n",
       "..                   ...                             ...   \n",
       "95  Kalenji By Decathlon    Women Platform Chelsea Boots   \n",
       "96              Red Tape       Men Court Royale Sneakers   \n",
       "97           Sir Corbett               Men Running Shoes   \n",
       "98                  Puma              Women Heeled Boots   \n",
       "99               El Paso                Men Runesy Shoes   \n",
       "\n",
       "                             Price  \n",
       "0                         Rs. 2699  \n",
       "1        Rs. 2009Rs. 2999(33% OFF)  \n",
       "2    Rs. 899Rs. 2599(Rs. 1700 OFF)  \n",
       "3        Rs. 1799Rs. 2999(40% OFF)  \n",
       "4         Rs. 724Rs. 2499(71% OFF)  \n",
       "..                             ...  \n",
       "95        Rs. 1597Rs. 1699(6% OFF)  \n",
       "96       Rs. 2099Rs. 6999(70% OFF)  \n",
       "97        Rs. 809Rs. 2699(70% OFF)  \n",
       "98       Rs. 3199Rs. 3999(20% OFF)  \n",
       "99  Rs. 1299Rs. 4799(Rs. 3500 OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists\n",
    "shoe_names=[]\n",
    "s_desc=[]\n",
    "short_desc=[]\n",
    "price=[]\n",
    "page_urls = []\n",
    "\n",
    "time.sleep(4)\n",
    "# scrape next pages urls\n",
    "nxt_page = driver.find_elements_by_xpath(\"//ul[@class='pagination-container']/li/a\")\n",
    "for i in nxt_page:\n",
    "    page_urls.append(i.get_attribute('href'))\n",
    "    \n",
    "\n",
    "for url in page_urls[:3]:\n",
    "    driver.get(url)\n",
    "    Names=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")  #for scrapping shoe brand names\n",
    "    for i in Names:\n",
    "        shoe_names.append(i.text)\n",
    "    \n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\") #for scrapping shoe short-description\n",
    "    for i in desc:\n",
    "        s_desc.append(i.text)\n",
    "    #As, the s_desc list contain blank description in every alternate index, so removing the blank or null description\n",
    "    for j in range(0,len(s_desc),2):\n",
    "        short_desc.append(s_desc[j])\n",
    "    \n",
    "    rs=driver.find_elements_by_xpath(\"//div[@class='product-price']\")  #for scrapping shoe prices\n",
    "    for i in rs:\n",
    "        price.append(i.text)    \n",
    "        \n",
    "df=pd.DataFrame({'Brand': shoe_names[:100],'Short-description': short_desc[:100],'Price': price[:100]})\n",
    "df        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031986cf",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/ \n",
    "Enter “Laptop” in the search field and then click the search icon. \n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image: \n",
    "    \n",
    "    After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop: \n",
    "1. Title \n",
    "2. Ratings \n",
    "3. Price \n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73956f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-92535f2ad7c5>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\")\n",
      "<ipython-input-14-92535f2ad7c5>:15: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
      "<ipython-input-14-92535f2ad7c5>:18: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')       # Locating search_button by xpath\n",
      "<ipython-input-14-92535f2ad7c5>:23: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
      "<ipython-input-14-92535f2ad7c5>:31: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
      "<ipython-input-14-92535f2ad7c5>:37: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
      "<ipython-input-14-92535f2ad7c5>:42: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")#collecting urls of all the laptop\n",
      "<ipython-input-14-92535f2ad7c5>:49: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  rating=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\")#locating the rating\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG Gram 17 Ultra-Light Intel Evo 11th Gen Core...</td>\n",
       "      <td>1,06,057</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG Gram 14 Ultralight Intel Evo 11th Gen Core ...</td>\n",
       "      <td>87,999</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>59,990</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acer Nitro 5 11th Gen Intel Core i7-11800H 15....</td>\n",
       "      <td>85,911</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo Legion 5 11th Gen Intel Core i7 15.6\"(3...</td>\n",
       "      <td>1,11,030</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14-inc...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>85,990</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Microsoft Surface Laptop Studio - 14.4\" Touchs...</td>\n",
       "      <td>3,73,999</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Dash F15 (2021) 15.6-inch (39.62 cms)...</td>\n",
       "      <td>1,09,990</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price       Ratings\n",
       "0  LG Gram 17 Ultra-Light Intel Evo 11th Gen Core...  1,06,057  4.4 out of 5\n",
       "1  LG Gram 14 Ultralight Intel Evo 11th Gen Core ...    87,999  4.1 out of 5\n",
       "2  HP Pavilion (2021) Intel 11th Gen Core i7 14 i...    84,990  4.3 out of 5\n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i7-1...    59,990  4.2 out of 5\n",
       "4  Acer Nitro 5 11th Gen Intel Core i7-11800H 15....    85,911  3.8 out of 5\n",
       "5  Lenovo Legion 5 11th Gen Intel Core i7 15.6\"(3...  1,11,030  4.4 out of 5\n",
       "6  HP Pavilion x360 11th Gen Intel Core i7 14-inc...    84,990  4.3 out of 5\n",
       "7  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....    85,990    4 out of 5\n",
       "8  Microsoft Surface Laptop Studio - 14.4\" Touchs...  3,73,999    4 out of 5\n",
       "9  ASUS TUF Dash F15 (2021) 15.6-inch (39.62 cms)...  1,09,990  4.2 out of 5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:/Users/91976/Downloads/chromedriver_win32/chromedriver\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.amazon.in/ref=nav_logo\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys(\"laptops\")                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')       # Locating search_button by xpath\n",
    "search_button.click()    \n",
    "\n",
    "time.sleep(2)\n",
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break\n",
    "        \n",
    "        \n",
    "#Scrapping Titles\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "    \n",
    "#scrapping Price\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)\n",
    "\n",
    "#locating Ratings\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")#collecting urls of all the laptop\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))#getting the url of first 10 laptops\n",
    "for url in UR:#loop for every laptop in the list\n",
    "    driver.get(url)\n",
    "    try:                  #exception handling for nosuchelementexception                                                    #click the rating link found\n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\")#locating the rating\n",
    "        Ratings.append(rating.text)#appending the ratings in Ratings list\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Ratings.append(\"NO rating\")#appending the No rating if no rating is there\n",
    "        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Title':Title,\n",
    "                'Price':price,\n",
    "                'Ratings':Ratings})\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766909c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
